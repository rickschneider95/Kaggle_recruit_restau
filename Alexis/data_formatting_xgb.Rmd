---
title: "format_data_xgb"
author: "Alexis Laks"
date: "29/11/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
library(onehot)
library(data.table)
library(mltools)
library(dplyr)
library(stringr)
library(lubridate)
library(caret)
library(purrr)
library(RcppRoll)
library(zoo)
```

This file will be dedicated to formatting the complete_data.csv file to feed to the xgb model.


## loading space according to your preferences: (:o)<--<

# HPG :

Do we really want to use the HPG info? We only have the reservations not the actual number of visits. The only way we could integrate them is to assume that for each reservation everyone showed up.

```{r}
ids <- read.csv("data/store_id_relation.csv")
ids
check <- hpg_reserve %>% inner_join(ids, by = "hpg_store_id") # actually not even sure we need to do this... or maybe for xgb since we only have air id's in the sample submission?
check <- check %>% mutate(id = as.character(air_store_id))

hpg_store_info
ccheck <- left_join(check,hpg_store_info,by = "hpg_store_id")

summary(is.na(ccheck)) # I checked, the NA's we have are there because we are missing them to begin with.

#14655 NAs in original data
#28,183 observations in the final data.
# either we get rid of the NA's, or we don't (left with 13528 obs) -> sol 1 ; sol 2
# either we change reserve visitors to visitors pretending all of them showed up or we don't use the hpg data AT ALL


# sol 1 :

sol1 <- na.omit(ccheck)
sol1 <- sol1 %>%
  mutate(visit_date = as.factor(str_sub(as.character(visit_datetime), start = 1, end = 10))) %>%
  rename(area_name = hpg_area_name) %>%
  rename(genre_name = hpg_genre_name) %>%
  rename(visitors = reserve_visitors) %>%
  select(id,visit_datetime,area_name,genre_name,longitude,latitude,visitors)
# rbind(data_air,sol1) <== TO APPLY ONLY IF WE CHOOSE THIS SOL°
data_air

# sol 2 :

sol2 <- sol2 %>%
  mutate(visit_date = as.factor(str_sub(as.character(visit_datetime), start = 1, end = 10))) %>%
  rename(area_name = hpg_area_name) %>%
  rename(genre_name = hpg_genre_name) %>%
  rename(visitors = reserve_visitors) %>%
  select(id,visit_datetime,area_name,genre_name,longitude,latitude,visitors)
# rbind(data_air,sol2) <== TO APPLY ONLY IF WE CHOOSE THIS SOL°
```

##WILL HAVE TO CHECK IF THE LATENCY-PEOPLE IN AIR IS SIGNIFICANTLY DIFFERENT FROM 0!
```{r}

```

to deleeeeteeeee:::::
# AIR :
<<<<<<< HEAD

While looking at this I found something weird, since we decided not to use the reservation info since we can't get them from the sample submission, we only need the air_visit_data and air_store_info and potentially the HPG data if we assume that the reserve visitors actually correspond to the real visitors (everyone showed up !)

## Without reserve info :

### Adding store info

```{r}
air_store_info <- read.csv("data/air_store_info.csv")
air_visit_data <- read.csv("data/air_visit_data.csv")
air_data <- full_join(air_visit_data,air_store_info, by = "air_store_id") %>%
  rename(id = air_store_id) %>%
  rename(genre_name = air_genre_name) %>%
  rename(area_name = air_area_name)

summary(is.na(air_data)) # No NA's.


=======

While looking at this I found something weird, since we decided not to use the reservation info since we can't get them from the sample submission, we only need the air_visit_data and air_store_info and potentially the HPG data if we assume that the reserve visitors actually correspond to the real visitors (everyone showed up !)

## Without reserve info :

### Adding store info

```{r}
air_store_info <- read.csv("data/air_store_info.csv")
air_visit_data <- read.csv("data/air_visit_data.csv")
air_data <- full_join(air_visit_data,air_store_info, by = "air_store_id") %>%
  rename(id = air_store_id) %>%
  rename(genre_name = air_genre_name) %>%
  rename(area_name = air_area_name)

summary(is.na(air_data)) # No NA's.
>>>>>>> Feature-engineering
```


### Adding date info

```{r}
<<<<<<< HEAD
date_info <- fread("data/date_info.csv")
=======
date_info <- read.csv("data/date_info.csv")
>>>>>>> Feature-engineering
date_info <- date_info %>%
  rename(visit_date = calendar_date)

summary(is.na(air_data)) # No NA's.
air_data <- left_join(air_data,date_info,by="visit_date") %>%
  rename(day_of_the_week_visit = day_of_week) %>%
  rename(holiday_flg_visit = holiday_flg) # CAREFULL, here it's an inner join, some days there were just no restaurants open

summary(is.na(air_data)) # No NA's.
names(air_data)
```

### total visits per date per id:

No need to sum over all reservations here since it's already done as such in the data.

## With reserve info :

```{r}
dataset <- read.csv("data/complete_data_final.csv")
```

# filtering for only air id's

```{r}
data_air <- dataset %>%
  filter(str_detect(id, "^air")) %>%
  filter(visitors != "NA") %>%
  select(-c(holiday_flg_visit,day_of_the_week_visit)) %>%  # I unselect these since they aren't correct
  select(-c(visit_time,reserve_date,reserve_time,reserve_visitors,day_of_the_week_reserve,holiday_flg_reserve)) # Can't use these as long as we don't have the method to implement them in time series

summary(is.na(data_air))
```

There are some minor NA problems with the data, just a slight problem with the complete dataset which we will solve in the following chunks:

### Fixing NA problems:

#### Genre, Area, Location (lon/lat)
for each id we have information on area name, lon, lat, and genre which do not vary in time. We are missing these infos for some id's but for others we don't. Despite having info on some id's they still had NA's for these variables so we just needed to extend this info.

```{r}
data_air %>% filter(id == "air_db80363d35f10926") %>% filter(visit_date == "2016-01-01") # wierd...

data_air <- data_air %>%
  group_by(id) %>%
  fill(c(genre_name,area_name,latitude,longitude))

summary(is.na(data_air))
```

There are still NA's but this is only because the info was missing to begin with.

#### Day of the week, holiday flag

We have info on what day of the week each visit date corresponds to and if that particular date is a holiday. This info spans on all the dates we have in all of our data but we still had NA's. I'll quickly resolve this by joining the date infos to our data.

```{r}
data_air <- inner_join(data_air,date_info,by="visit_date") %>%
  rename(day_of_the_week_visit = day_of_week) %>%
  rename(holiday_flg_visit = holiday_flg) # CAREFULL, here it's an inner join, some days there were just no restaurants open

summary(is.na(data_air))
```

And there we have it! a complete dataset with no NA's in dates and visitors, only some in the features we have regarding the identifiers but this is only due to the fact that they were missing to begin with!

### Counting nb of reservations per date per id:

```{r}
data_air <- data_air %>%
  mutate(nb_res = 1) %>%
  group_by(id,visit_date) %>%
  mutate(nb_res = sum(nb_res))

levels(as.factor(data_air$nb_res)) # different nb of reservations in the data! note: info coming from visit data is already summed so it's normal to get only one reservation that's huge...
```

## Formatting for one hot encoding:

There is a big question in regards to what we shall do with the info from the air_reserve data. We have info on the time of the visit and the data AND time of the reservation as well as count in reservation but only on ~300 of the ~800 id's we have in the air_visit data (date on visit date and number of visitors => WHAT WE'RE TRYING TO PREDICT).
With this info from air reserve we would be able to see the differences in the number of people who actually showed up, how much time did they reserve in advance to get an idea of hwo fancy the restaurant is etc.. We're missing a lot of data on that so what should we do?
The XGB algo has to train on vars that exist in the sample submission, since in the sample submission we only have the id and the date the only info we'll be able to retrieve is:

- day of the week (from the date)
- holiday flag (from the date)
- genre (from the id)
- area name (from the id)

We can then create more variables BUT ONLY from these vars that we are able to collect from the sample submission. So how are we supposed to use all the reserve info?

For now I'll go on assuming that the reserve info is useless and only construct on variables that we can retrieve from the info in the sample submission. You will still find functions that can work with the reserve data but I won't be using them, at least for now.

In the sample submission we have unique rows with an identifier and a given date. Here we often have several rows containing the same identifier and the same date but not the same number of visitors. This makes sense since you will have several different groups of costumers throughout the day. We want to regroup all the visits on a given date for a given identifier since this is what we're trying to predict!

# Grouping visits per day per id:

```{r}
data_air <- data_air %>%
  group_by(id,visit_date,genre_name,latitude,longitude,area_name,day_of_the_week_visit,holiday_flg_visit,nb_res) %>%
  summarise(visitors = sum(visitors)) %>%
  ungroup()

n_occur <- data.frame(table(data_air$id,data_air$visit_date))
n_occur[n_occur$Freq > 1,] #Problem with the original csv.

summary(is.na(data_air))

data_air %>% filter(id == "air_db80363d35f10926") %>% filter(visit_date == "2016-01-01")
```



We will need to use the air_data (based only on date_info, air_visit_data, air_store_info) rather than data_air (using all datasets) until we find a solution for the time series improved prediction.

## ONE HOT ENCODING ON FIRST BASE VARS

Now that dataset has been created : 
```{r}
air_data <- read.csv("data/air_data.csv")
```


This is the one hot encoding section (under form of functions) for the variables we start with in the complete dataset. Splitting them into functions was a conscious choice that gives us more flexibility as to what we want to one-hot encode, if we want to change the code at a later time.

# One hot encoding for VISIT day:

Unoptimal, I'll create a better function below separating start of month to end of month ;)

```{r}
vday_transf <- function(data){
  one_h <- data %>%
    select(visit_date) %>%
    map(str_sub, start = 9, end = 10) %>%
    map(as.factor) %>%
    map(as.data.table) %>%
    map(one_hot)
  data <- data %>% cbind(one_h)
}
```

# One hot encoding for RESERVE day:

Same as visit, there exists a better way to do it. Check the feature engineering section!

```{r}
rday_transf <- function(data){
  one_h <- data %>%
    select(reserve_date) %>%
    map(str_sub, start = 9, end = 10) %>%
    map(as.factor) %>%
    map(as.data.table) %>%
    map(one_hot)
  data <- data %>% cbind(one_h)
}
```

# One hot encoding for VISIT time:

```{r}
vtime_transf <- function(data){
  one_h <- data %>%
    select(visit_time) %>%
    map(str_sub, start = 0, end = 3) %>%
    map(as.factor) %>%
    map(as.data.table) %>%
    map(one_hot)
  data <- data %>% cbind(one_h)
}
```

# One hot encoding for RESERVE time:

```{r}
rtime_transf <- function(data){
  one_h <- data %>%
    select(reserve_time) %>%
    map(str_sub, start = 0, end = 3) %>%
    map(as.factor) %>%
    map(as.data.table) %>%
    map(one_hot)
  data <- data %>% cbind(one_h)
}
```

# One hot encoding for reserve MONTH:

```{r}
rmonth_transf <- function(data){
  one_h <- data %>%
    select(reserve_date) %>%
    map(str_sub, start = 6, end = 7) %>%
    map(as.factor) %>%
    map(as.data.table) %>%
    map(one_hot)
  data <- data %>% cbind(one_h)
}
```

# One hot encoding for visit MONTH:

```{r}
vmonth_transf <- function(data){
  one_h <- data %>%
    select(visit_date) %>%
    map(str_sub, start = 6, end = 7) %>%
    map(as.factor) %>%
    map(as.data.table) %>%
    map(one_hot)
  data <- data %>% cbind(one_h)
}
```

# One hot encoding for reserve YEAR:

```{r}
ryear_transf <- function(data){
  one_h <- data %>%
    select(reserve_date) %>%
    map(str_sub, start = 1, end = 4) %>%
    map(as.factor) %>%
    map(as.data.table) %>%
    map(one_hot)
  data <- data %>% cbind(one_h)
}
```

# One hot encoding for visit YEAR:

```{r}
vyear_transf <- function(data){
  one_h <- data %>%
    select(visit_date) %>%
    map(str_sub, start = 1, end = 4) %>%
    map(as.factor) %>%
    map(as.data.table) %>%
    map(one_hot)
  data <- data %>% cbind(one_h)
}
```

# One hot encoding AREA:

This is the one hot encoder function for the original area name variable. I don't recommend using at as it create way too many entries, instead in the FEATURE ENGINEERING part of this rmd that you'll find below, there is an adapted function which keeps all the info while generating way less entries. Still, here's a glimpse at the transformation on the original variable:

```{r}
basic_area_transf <- function(data){
  one_h <- data %>%
    select(area_name) %>%
    map(as.character) %>%
    mutate(area_name = case_when(area_name == "Osaka Prefecture Osaka None" ~ "Ōsaka-fu Prefecture Osaka None",
                                 TRUE ~ area_name)) %>% ## This is just an error in the data set
    map(as.factor) %>%
    map(as.data.table) %>%
    map(one_hot)
  try <- data %>% cbind(one_h)
}
```

# One hot encoding for DAY OF THE WEEK RESERVE:

```{r}
rdayweek_transf <- function(data){
  one_h <- data %>%
    select(day_of_the_week_reserve) %>%
    map(as.data.table) %>%
    map(one_hot)
  data <- data %>% cbind(one_h)
}
```

# One hot encoding for DAY OF THE WEEK VISIT:

```{r}
vdayweek_transf <- function(data){
  one_h <- data %>%
    select(day_of_the_week_visit) %>% # Already factor
    map(as.data.table) %>%
    map(one_hot)
  data <- data %>% cbind(one_h)
}
```

# One hot encoding for LONGITUDE:

```{r}
lat_transf <- function(data){
  one_h <- data %>%
    select(longitude) %>%
    map(round, digits = 1) %>%
    map(as.factor) %>%
    map(as.data.table) %>%
    map(one_hot)
  data <- data %>% cbind(one_h)
}
```

# One hot encoding for LATITUDE:

```{r}
lon_transf <- function(data){
  one_h <- data %>%
    select(latitude) %>%
    map(round, digits = 1) %>%
    map(as.factor) %>%
    map(as.data.table) %>%
    map(one_hot)
  data <- data %>% cbind(one_h)
}
```

# One hot encoding for VISIT holiday flag:

```{r}
vholflg_transf <- function(data){
  one_h <- data %>%
    select(holiday_flg_visit) %>%
    map(as.factor) %>%
    map(as.data.table) %>%
    map(one_hot)
  data <- data %>% cbind(one_h)
}
```

# One hot encoding for RESERVE holiday flag

```{r}
rholflg_transf <- function(data){
  one_h <- data %>%
    select(holiday_flg_reserve) %>%
    map(as.factor) %>%
    map(as.data.table) %>%
    map(one_hot)
  data <- data %>% cbind(one_h)
}
```

# One hot encoding for GENRE :

We get a lot of different levels for genre which is normal, but from the eda of the air csv files we see that some genres in the data are almost unvisited. It could be interesting to get only the significant genres (at least more than a thousand visits). I'll create that function in the feature engineering part:

```{r}
genre_transf <- function(data){
  one_h <- data %>%
    select(genre_name) %>%
    map(as.data.table) %>%
    map(one_hot)
  data <- data %>% cbind(one_h)
}
```

## FEATURE ENGINEERING:

**Creating new variables and one-hot encoding them for xgb program**

# Works for both

## One hot encoding (Better version) AREA:

There are many different levels for area names, although they all appartain to one particular city. I'll regroup observations appartaining to the same big city (Tokyo, Kyoto, Osaka, etc...) and onehot encode on this smaller amount of levels.

```{r}
area_transf <- function(data){
  one_h <- data %>%
    select(area_name) %>%
    mutate(area_name = as.character(area_name)) %>%
    mutate(area_name = case_when(area_name == "Osaka Prefecture Osaka None" ~ "Ōsaka-fu Prefecture Osaka None",
                                                                       TRUE ~ area_name)) %>% # error in the data
    map(str_sub, start = 0, end = 8) %>%
    map(as.factor) %>%
    map(as.data.table) %>%
    map(one_hot)
  data <- data %>% cbind(one_h)
}
```

Difference is huge, we get 15 levels with the above function vs 130 from the basic one. TAKE THIS ONE PLEASE SENPAI

## one hot encoding for VISIT start/end of the month :

The idea behind this function is that costumers might be more encline to go to the restaurant in the first part of the month  rather than in the middel or at the end. So instead of creating dummies for each possible day in the month I'll just categorize them acoording to their situation in the month:

```{r}
bme_vmonth_transf <- function(data){
  one_h <- data %>%
    select(visit_date) %>%
    mutate(visit_date = as.character(str_sub(visit_date, start = 9, end = 10))) %>%
    mutate(visit_date = as.factor(case_when(visit_date >= 0 & visit_date <= 12 ~ "beginning",
                                           visit_date >= 13 & visit_date <= 22 ~ "middle",
                                                                          TRUE ~ "end"))) %>%
    map(as.data.table) %>%
    map(one_hot)
  data <- data %>% cbind(one_h)
}
```

## one hot encoding for regrouped GENRE :

```{r}
genre_gr_transf <- function(data){
  one_h <- data %>%
    select(genre_name) %>%
    mutate(genre_name = case_when(genre_name == "Izakaya" |
                                    genre_name == "Okonomiyaki/Monja/Teppanyaki" |
                                      genre_name == "Japanese food in general" |
                                        genre_name == "Japanese cuisine/Kaiseki" ~ "Japanese food",
                                  genre_name == "Italian/French" |
                                    genre_name == "Italian" ~ "Western food",
                                  genre_name == "Creative cuisine" |
                                    genre_name == "Creative Japanese food" ~ "Creation",
                                  genre_name == "Karaoke" |
                                    genre_name == "Party" |
                                      genre_name == "Karaoke/Party" ~ "Amusement bar",
                                  genre_name == "Asian" ~ "Yakiniku/Korean food",
                                  genre_name == "Cafe/Sweets" ~ "Cafe",
                                  genre_name == "Steak/Hamburger/Curry" ~ "Grilled meat",
                                  TRUE ~ as.character(genre_name))) %>%
    map(as.factor) %>%
    map(as.data.table) %>%
    map(one_hot)
    data <- data %>% cbind(one_h)
}
<<<<<<< HEAD

test %>% group_by(genre_name) %>% summarise(total = n()) # Checks to give insight for re-arrangement.
=======
>>>>>>> Feature-engineering
```

## one hot encoding for bar/restaurant separation:

```{r}
barrest_transf <- function(data){
  one_h <- data %>%
    select(genre_name) %>%
    mutate(genre_name = case_when(genre_name == "Asian" |
                                    genre_name == "Okonomiyaki/Monja/Teppanyaki" |
                                      genre_name == "Japanese food" |
                                        genre_name == "Western food" |
                                          genre_name == "Italian/French" |
                                            genre_name == "International cuisine" |
                                              genre_name == "Yakiniku/Korean food" |
                                                genre_name == "Izakaya" |
                                                  genre_name == "Creative cuisine" ~ "Restaurant",
                                                genre_name == "Dining bar" |
                                                  genre_name == "Bar/Cocktail" |
                                                    genre_name == "Karaoke/Party" |
                                                       genre_name == "Cafe/Sweets" ~ "Bar",
                                                                              TRUE ~ "Else")) %>%
    map(as.factor) %>%
    map(as.data.table) %>%
    map(one_hot)
    data <- data %>% cbind(one_h)
}
```

## One hot encoding for golden week:

28th of April to 6th of may

```{r}
goldw_transf <- function(data){
  one_h <- data %>%
    mutate(visit_date = ymd(visit_date)) %>%
    mutate(goldenweek = case_when(visit_date > ymd("20160428") & visit_date < ymd("20160507") ~ 1,
                                  visit_date > ymd("20170428") & visit_date < ymd("20170507") ~ 1,
                                                                                         TRUE ~ 0)) %>%
    select(goldenweek) %>%
    map(as.factor) %>%
    map(as.data.table) %>%
    map(one_hot)
  data <- data %>% cbind(one_h)
}
```

## One hot encoding for holiday days of the golden week

29th of April, 3rd, 4th and 5th of May

```{r}
goldd_transf <- function(data){
  one_h <- data %>%
    mutate(visit_date = ymd(visit_date)) %>%
    mutate(goldendays = case_when(visit_date == ymd("20160429") |
                                    visit_date == ymd("20160503") |
                                      visit_date == ymd("20160504") |
                                        visit_date == ymd("20160505") |
                                  visit_date == ymd("20170429") |
                                    visit_date == ymd("20170503") |
                                      visit_date == ymd("20170504") |
                                        visit_date == ymd("20170505") ~ 1,
                                                                 TRUE ~ 0)) %>%
    select(goldendays) %>%
    map(as.factor) %>%
    map(as.data.table) %>%
    map(one_hot)
  data <- data %>% cbind(one_h)
}
```

## One hot encoding for WEEKEND :

```{r}
wknd_transf <- function(data){
  one_h <- data %>%
    mutate(wknd = case_when(day_of_the_week_visit == "Friday" |
                            day_of_the_week_visit == "Saturday" |
                            day_of_the_week_visit == "Sunday" ~ "weekend",
                                                         TRUE ~ "weekday")) %>%
    select(wknd) %>%
    map(as.factor) %>%
    map(as.data.table) %>%
    map(one_hot)
  data <- data %>% cbind(one_h)
}
```

<<<<<<< HEAD
=======
## one hot encoding for welth per area :

One hot encoding according to mean GDP per capita per areas in Japan !

```{r}
wealth_transf <- function(data){
  one_h <- data %>%
    mutate(area_name = as.character(area_name)) %>% 
    mutate(area_name = case_when(area_name == "Osaka Prefecture Osaka None" ~ "Ōsaka-fu Prefecture Osaka None",
                                                                       TRUE ~ area_name)) %>% # error in the data
    mutate(area_name = str_sub(area_name, start = 0, end = 8)) %>% 
    mutate(wealth = case_when(area_name == "Tōkyō-to" ~ "High",
                              area_name == "Shizuoka" | area_name == "Hyōgo-ke" | area_name == "Ōsaka-fu" ~ "Middle/High",
                              area_name == "Niigata-" | area_name == "Miyagi-k" | area_name == "Hokkaidō" ~ "Middle",
                              area_name == "Fukuoka-" ~ "Middle/Low",
                              TRUE ~ "Low")) %>% 
    select(wealth) %>% 
    map(as.factor) %>% 
    map(as.data.table) %>% 
    map(one_hot)
  data <- data %>% cbind(one_h)
}
```

## extract nth day of the year

```{r}
nth_day_trasnf <- function(data){
  days <- c(1:365,1:152)
  dates <- date_info %>%
    cbind(days) %>% 
    select(visit_date,days)
  data <- data %>%
    left_join(dates, by = "visit_date") 
}
```

## one hot encoding for holidays

The rationale behind the next transformation is that days prior and after actual holidays, people might feel joyful, or take holidays (even though Japanese people do not take that many holidays), and it might influence the number of people going to restaurants.
```{r}
#if holiday==1 (there is a holiday) then 2 days before and after transform to 2, creating a new category to take the "holiday feels" effect into account
test <- air_data %>%
  mutate(holiday_flg_visit = case_when(
    (lead(holiday_flg_visit,1)==1)&(holiday_flg_visit==0) ~ 2, #if next row holiday_flg_visit has a certain value, and holiday flag visit has a normal value, then return 2.
    lead(holiday_flg_visit,2)==1&(holiday_flg_visit==0) ~ 2,
    lag(holiday_flg_visit,1)==1&(holiday_flg_visit==0) ~ 2,
    lag(holiday_flg_visit,2)==1&(holiday_flg_visit==0) ~ 2,
    TRUE ~ as.numeric(holiday_flg_visit)
  ))
```
>>>>>>> Feature-engineering

# Works only for data_air (reservation infos)

## One hot encoding for NUMBER OF RES:

By counting the number of services for each date for each ID we can know how many reservations there were in a day. We can then also derive the average number of people per reservations:

```{r}
dn_transf <- function(data){
  one_h <- data %>%
    select(visit_time) %>%
    mutate(visit_time = as.integer(str_sub(as.character(visit_time),
                                  start = 0,
                                  end = 3))) %>%
    mutate(visit_time = case_when(visit_time >= 4 & visit_time <= 16 ~ "noon",          # Lunch
                                                                TRUE ~ "night")) %>%    # Dinner
    map(as.factor) %>%
    map(as.data.table) %>%
    map(one_hot)
  data <- data %>% cbind(one_h)
}
```

## one hot encoding for LATENCY

```{r}
latency_transf <- function(data){
  one_h <- data
  one_h <- one_h %>%
    mutate(latency_days = as.integer(ifelse(is.na(reserve_date), 0, as.numeric(as.Date(visit_date) - as.Date(reserve_date))))) %>%
    select(latency_days) %>%
    mutate(latency_days = as.factor(case_when(latency_days >= 0 & latency_days <= 15 ~ "casual",
                                              latency_days > 15 & latency_days <= 45 ~ "fancy",
                                                                                TRUE ~ "very fancy")))
  one_h <- one_hot(as.data.table(one_h))
  data <- data %>% cbind(one_h)
}
```

## one hot encoding for RESERVE start/end of the month :

same as above but for reservation date!

```{r}
bme_rmonth_transf <- function(data){
  one_h <- data
  one_h$reserve_date <- as.integer(str_sub(as.character(one_h$reserve_date), start = 9, end = 10))
  one_h <- one_h %>%
    select(reserve_date) %>%
    mutate(reserve_date = as.factor(case_when(reserve_date >= 0 & reserve_date <= 12 ~ "beginning",
                                           reserve_date >= 13 & reserve_date <= 22 ~ "middle",
                                                                          TRUE ~ "end")))
  one_h <- one_hot(as.data.table(one_h))
  data <- data %>% cbind(one_h)
}
```

# one hot encoding for nb visits/reservation

Needs improvement, we get around 200 new columns from one hot encoding so we should create categories:
- small rest <= 20
- small/medium > 20 <= 50
- medium > 50 <= 90
- medium/large >90 <= 150
- large > 150

we can change according to preferences but here's the baseline of the function! (need to use case_when):

```{r}
average_transf <- function(data){
  one_h <- data %>%
    mutate(av_per_day = round(visitors/nb_res)) %>%
    select(av_per_day) %>%
    map(as.factor) %>%
    map(as.data.table) %>%
    map(one_hot)
  data <- data %>% cbind(one_h)
}
<<<<<<< HEAD
=======
```

```{r}
data_new <- air_data

sample_try <- sample_try  %>% group_by(id) %>% 
  mutate(lag_1 = lag(visitors, 1),
         lag_2 = lag(visitors, 2),
         lag_3 = lag(visitors, 3),
         lag_4 = lag(visitors, 4),
         lag_5 = lag(visitors, 5),
         lag_6 = lag(visitors, 6),
         lag_7 = lag(visitors, 7),
         lag_8 = lag(visitors, 8),
         lag_9 = lag(visitors, 9),
         lag_10 = lag(visitors, 10),
         lag_11 = lag(visitors, 11),
         lag_12 = lag(visitors, 12),
         lag_13 = lag(visitors, 13),
         lag_14 = lag(visitors, 14),
         lag_15 = lag(visitors, 15),
         lag_16 = lag(visitors, 16),
         lag_17 = lag(visitors, 17),
         lag_18 = lag(visitors, 18),
         lag_19 = lag(visitors, 19),
         lag_20 = lag(visitors, 20),
         lag_21 = lag(visitors, 21),
         lag_22 = lag(visitors, 22),
         lag_23 = lag(visitors, 23),
         lag_24 = lag(visitors, 24),
         lag_25 = lag(visitors, 25),
         lag_26 = lag(visitors, 26),
         lag_27 = lag(visitors, 27),
         lag_28 = lag(visitors, 28),
         lag_30 = lag(visitors, 30),
         lag_33 = lag(visitors, 33),
         lag_36 = lag(visitors, 36),
         lag_39 = lag(visitors, 39),
         lag_40 = lag(visitors, 40),
         lag_50 = lag(visitors, 50),
         lag_60 = lag(visitors, 60),
         lag_70 = lag(visitors, 70),
         lag_80 = lag(visitors, 80),
         lag_90 = lag(visitors, 90),
         lag_100 = lag(visitors, 100),
         lag_120 = lag(visitors, 120),
         lag_150 = lag(visitors, 150),
         lag_180 = lag(visitors, 180),
         avg_7 = lag(roll_meanr(visitors, 7), 1),
         avg_3 = lag(roll_meanr(visitors, 3), 1),
         avg_7 = lag(roll_meanr(visitors, 7), 1),
         avg_14 = lag(roll_meanr(visitors, 14), 1),
         avg_21 = lag(roll_meanr(visitors, 21), 1),
         avg_28 = lag(roll_meanr(visitors, 28), 1),
         avg_50 = lag(roll_meanr(visitors, 50), 1),
         avg_100 = lag(roll_meanr(visitors, 100), 1),
         avg_150 = lag(roll_meanr(visitors, 150), 1),
         avg_200 = lag(roll_meanr(visitors, 200), 1),
         avg_250 = lag(roll_meanr(visitors, 250), 1),
         avg_300 = lag(roll_meanr(visitors, 300), 1)
         )
>>>>>>> Feature-engineering
```


## TRY CHUNK ( TRY MY CHUNK (:^<) )

this chunk is for you to test out the different one hot encoding functions. have fun. (these are actually all the functions that will go in the package!!)

```{r}
try <- air_data

# Transf functions on basic vars:
try <- nth_day_trasnf(try)
try <- vmonth_transf(try)
try <- vyear_transf(try)
try <- area_transf(try)
try <- genre_gr_transf(try)
try <- vdayweek_transf(try)
try <- bme_vmonth_transf(try)
try <- vholflg_transf(try)
try <- lat_transf(try)
try <- lon_transf(try)
try <- goldd_transf(try)
try <- goldw_transf(try)
try <- barrest_transf(try)
try <- wknd_transf(try)
<<<<<<< HEAD


=======
try <- wealth_transf(try)
>>>>>>> Feature-engineering

try

# Transf functions on reserve vars (can't use for now):

try <- rtime_transf(try)
try <- vtime_transf(try)
try <- rmonth_transf(try)
try <- ryear_transf(try)
try <- dn_transf(try)
try <- rdayweek_transf(try)
try <- latency_transf(try)


# Obsolete bin :

try <- basic_area_transf(try)

## To debug bin:

```

# Sample submission feature engineering :
```{r}
sample_try <- read.csv("data/submission_data.csv") %>% 
  rename(visit_date = predict_date) %>% 
  rename(day_of_the_week_visit = day_of_week) %>% 
  rename(holiday_flg_visit = holiday_flg)

sample_try <- nth_day_trasnf(sample_try)
sample_try <- vmonth_transf(sample_try)
sample_try <- vyear_transf(sample_try)
sample_try <- area_transf(sample_try)
sample_try <- genre_gr_transf(sample_try)
sample_try <- vdayweek_transf(sample_try)
sample_try <- bme_vmonth_transf(sample_try)
sample_try <- vholflg_transf(sample_try)
sample_try <- lat_transf(sample_try)
sample_try <- lon_transf(sample_try)
sample_try <- goldd_transf(sample_try)
sample_try <- goldw_transf(sample_try)
sample_try <- barrest_transf(sample_try)
sample_try <- wknd_transf(sample_try)
sample_try <- wealth_transf(sample_try)
```


**NOTES**

- Need to one hot code genres! *SOLVED*

- replace reservation times by average diff in res/visit for each ID !!! *SOLVED*

-group_by id,date and summarise -> get the total number of visits per day. (per noon,night?)
      => solution: seperate data set in visits for noon/ visits for ngiht and run xgb on each separately NO -- *SOLVED*

-We're taking out lon/lat for now, we already have the area name for location info (there still is a function to one hot code it though just in case) CAREFUL it creates like 130 columns LMA0 *SOLVED*

- genre names has a lot of NA's. Also I had the idea to keep only the top categories, but that means taking out data from our complete dataset that is already deprived. Not sure it's the good way to go. We could although consider regrouping genres together when they are resemblant! (might lose precision) ==> UPDATE : this actually can't work. We're taking out observations so it's just messing the dataframe. *SOLVED*

WHAT WE CAN DO, is regroup genres according to their similarities in the complete dataset. If e do it after hand we won't be able to retrieve genres for some id's in the sample submission. *SOLVED*

```{r}
data_air %>% group_by(genre_name) %>% summarise(total = n()) %>% arrange(desc(total))
```

 -> Izakaya is a sort of café/bistro we can regroup with Okonomiyaki/Monja/Teppanyaki which is also japanese cuisine
 -> Okonomiyaki/Monja/Teppanyaki is japanese cuisine, we can regroup with Japanese food, Japanese food in general, Japanese cuisine/Kaiseki
 -> Italian/French can go with western food, Italian
 -> Creation can go with creative cuisine
 -> Karaoke/Party can go with Party, Karaoke and Amusement bar
 -> Aisan can go with Yakiniku/Korean food
 -> Cafe/Sweets can go with Cafe
 -> Steak/Hamburger/Curry can go with Grilled meat
 -> Bar/Cocktail with amusement bar??

LOOK AT genre_gr_transf :))

- We have NA's for day of the week reserve and day of the week visit: *SOLVED*

```{r}
sum(is.na(data_air$day_of_the_week_reserve))
sum(is.na(data$day_of_the_week_visit))
```

# ONE HOT XGB CSV CREATION CHUNK

```{r}
<<<<<<< HEAD
try <- try[,-c(4:9)]


#CHANFE LAST NUMBER EVERY NEW VERSION:
write.csv(try, "data/data_1h_xgb_CORRECT_4.csv", row.names = FALSE)

trytry <- read.csv("data/data_1h_xgb_CORRECT_4.csv")
=======
sample_try <- sample_try[,-c(4:9)]


#CHANFE LAST NUMBER EVERY NEW VERSION:
write.csv(sample_try, "data/data_1h_xgb_samplesubmission.csv", row.names = FALSE)

trytry <- read.csv("data/data_1h_xgb_samplesubmission.csv")
>>>>>>> Feature-engineering

# Checks :
n_occur <- data.frame(table(trytry$id,trytry$visit_date))
n_occur[n_occur$Freq > 1,]  # No duplicates

summary(is.na(trytry)) # No NA's except for timeseries features

trytry # we good fam
```

Seems there is a small problem with the complete csv.



Louis workspace:

A SUPPRIMER @ALEXIS????

That should be in the complete data set rmd actually, it can be usefull but it's for later improvements.

# Change dataframe
```{r}
data <- data %>%
  mutate(day_visit = day(dmy(visit_date)), #extract visit day from date
         day_reserve = day(dmy(reserve_date)),  #extract reserve day from date
         month_visit = month(dmy(visit_date)),   #extract visit month from date
         month_reserve = month(dmy(reserve_date)), #extract reserve month from date
         year_visit = year(dmy(visit_date)), #extract visit year from date
         year_reserve = year(dmy(visit_date)), #extract reserve year from date
         latency_days=ifelse(is.na(reserve_date),0,as.numeric(as.Date(visit_date)-as.Date(reserve_date))), #days between reservation vs visit. if no reservation then will be 0
         latency_people=ifelse(is.na(reserve_visitors),0,visitors-reserve_visitors),
         visit_time=as.factor(str_sub(as.character(visit_time), start = 0, end = 3)),
        reserve_time = as.factor(str_sub(as.character(reserve_time), start = 0, end = 3)),
        reserve_date = as.factor(str_sub(as.character(reserve_date), start = 6, end = 7)),
        visit_date=as.factor(str_sub(as.character(visit_date), start = 6, end = 7))) #difference in the number of people from the party between reservation vs visit. if no reservation then will be 0

# dummify the data
dmy <- dummyVars(" ~ .", data = data)
trsf <- data.frame(predict(dmy, newdata = customers))
trsf

one_h$reserve_date <- as.factor(str_sub(as.character(one_h$reserve_date), start = 0, end = 4))
visit_date <- as.factor(str_sub(as.character(one_h$visit_date), start = 0, end = 4))
area_name = as.factor(substr(area_name, 0, 8))
ne_h$day_of_the_week_visit <- as.factor(one_h$day_of_the_week_visit)
one_h$day_of_the_week_reserve <- as.factor(one_h$day_of_the_week_visit)

```

# data change
```{r}
datal <- dataset %>%
  mutate(day_visit = day(dmy(visit_date)), #extract visit day from date
         day_reserve = day(dmy(reserve_date)),  #extract reserve day from date
         month_visit = month(dmy(visit_date)),   #extract visit month from date
         month_reserve = month(dmy(reserve_date)), #extract reserve month from date
         year_visit = year(dmy(visit_date)), #extract visit year from date
         year_reserve = year(dmy(visit_date)), #extract reserve year from date
         latency_days=ifelse(is.na(reserve_date),0,as.numeric(as.Date(visit_date)-as.Date(reserve_date))), #days between reservation vs visit. if no reservation then will be 0
         latency_people=ifelse(is.na(reserve_visitors),0,visitors-reserve_visitors)) #difference in the number of people from the party between reservation vs visit. if no reservation then will be 0
```
FIN DE SUPPRESSION POTENTIELLE????


These are many different tries.. OBSOLETE BIN:

```{r}
append_1 <- data_air %>%
  group_by(id,visit_date,genre_name,latitude,longitude,area_name) %>%
  summarise(visitors = sum(visitors))

append_2 <- data_air %>%
  group_by(id,visit_date) %>%
  summarise(reserve_visitors = sum(reserve_visitors))

append_final <- full_join(append_1,append_2, by = c("id","visit_date"))

date_infos <- data_air %>%
  select(visit_date,day_of_the_week_visit,holiday_flg_visit) %>%
  distinct(visit_date,day_of_the_week_visit,holiday_flg_visit)

left_join(append,date_infos,by = "visit_date") %>% distinct(id,genre_name,latitude,longitude,area_name,visitors,reserve_visitors,visit_date,day_of_the_week_visit,holiday_flg_visit)



summary(is.na(append))




dates_id <- append[,1:2]

data_air %>% filter()

data_air <- data_air %>%
  select(-c(visitors,reserve_visitors))

dataset_full <- le_join(append,data_air,by = c("id","visit_date"))

try <- data_air
try1 <- left_join(try,append_1, by = c("id","visit_date"))
try2 <- left_join(try1,append_2, by = c("id","visit_date"))
try3 <- left_join
try2

  sum(is.na(append_2$reserve_visitors))
sum(is.na(data_air))

sum(is.na(dataset$reserve_visitors))
try <- data_air %>% group_by(id) %>% fill(c(genre_name,area_name,latitude,longitude))

# TESTS

nrow(try)
nrow(data_air)
summary(is.na(try))
summary(is.na(data_air))
try %>% filter(id == "air_034a3d5b40d5b1b1")
try <- try %>% select(-c(day_of_the_week_visit,holiday_flg_visit))

# try <- try %>% group_by(visit_date) %>% fill(c(day_of_the_week_visit,holiday_flg_visit))
date_info <- date_info %>% rename(visit_date = calendar_date)
try2 <- full_join(try,date_info,by="visit_date")
summary(is.na(try2))


date_info
levels(as.factor(try$visit_date))
```





# IMAGINATION LAND

this where you come to rest your eyes and think of what crazy variables you shall create from this anorexic dataset.. (microdosing not allowed ;) )

```{r}
air_data
```

-> seperate Bars from Restaurants ? *DONE*
-> select certain days/months to be more important? golden week !! *DONE*
-> certain areas of japan richer than others? (get wealth distribution plots of japan !!)
-> create week-end variable to put more weight on consumption on weekends? (eda showed this was true!)
-> create mean visitors per month or and year variable and categorize it if two many levels? (round it!)
