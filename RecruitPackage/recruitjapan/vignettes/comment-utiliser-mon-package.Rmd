---
title: "Transforming basic data with recruitjap"
author: "Alexis Laks"
date: "04/12/2018"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r}
# library(recruitjap)
```


This package conatins a set of functions to one hot encode categorical variables that are in our complete dataset to feed to the XGBoost algorithm for prediction. 

You will find one hot encoding functions for the basic vars that are given in the datasets from Kaggle that we joined into one complete dataset (air_data). In this data you will find : 

- id : Identifier for each restaurant in our data
- visit_date : All dates were each restaurant had visitors
- genre_name : The style of the restaurant (it can be japanese food, a bar, a karaoke ...)
- area_name : It's approximate location (generally located in one of the prefectures of a big city in Japan)
- holiday_flg_visit : variable taking value one when visit_date is a holiday in Japan 
- day_of_the_week_visit : Indicates to which day of the week corresponds the date (ex: Sunday, Tuesday, ...)
- longitude : approximate longitude coordinates for each restaurant
- latitude : approximate latitude coordinates for each restaurant

There will also be a set of functions that can be used on more data we have regarding reservations, reservation times, data from another reservation platform (HPG) although these data are useless for our Kaggle submission. This is due to the fact that from the sample submission we have only 3 variables : 
 - id : an id for which to forecast
 - visit_date : a date for which to forecast
 - visitors : the variable to predict
 
From these 3 variables unfortunately we can only retrieve the varaibles mentionned above which correspond to the joining of 3 datasets imported from kaggle (air_visit_data.csv, air_store_info.csv, date_info.csv).
This is why all these functions are directly created for our complete data, all the reserve functions that do not work on this complete dataset are listed as such and are kept for future improvements if the reservation data for the sample submission is made available. 

You will find this vignette organised as follows :

1. Functions to one hot encode base categorical variables for air_data
2. Functions to one hot encode other categorical variables for which data is partially unavailable
3. Functions for the variables created by our feature engineering team (vars created from base vars) 
4. Functions for the variables created by our feature engineering team working only on enhanced (not working) dataset 

We decided to keep the functions that could encode the uncomplete reservation varaibles as a way to improve this package in the future.

#1. One-hot encoding on basic vars for air_data

## One hot encoding for VISIT day:

Hot encodes every day in a month, so you'll get a 1 in the one hot for day.01 when observation is at 01/01/2016.

```{r}
# test <- air_data
# test <- vday_transf(test)
```

## One hot encoding for visit MONTH:

Same principle but for the 12 months of a year.

```{r}
# test <- vmonth_transf(test)
```

## One hot encoding for visit YEAR:

Again the same principle but for all the years considered in our data.

```{r}
# test <- vyear_transf(test)
```

## One hot encoding AREA:

This is the one hot encoder function for the original area name variable. I don't recommend using at as it create way too many entries, instead in the FEATURE ENGINEERING part of this rmd that you'll find below, there is an adapted function which keeps all the info while generating way less entries. Still, here's a glimpse at the transformation on the original variable:

```{r}
# test <- basic_area_transf(test)
```

## One hot encoding for DAY OF THE WEEK VISIT:

Hot encodes for all the days in the week, if it's a monday then var.monday will take value 1 etc...

```{r}
# test <- vdayweek_transf(test)
```

## One hot encoding for LONGITUDE & LATITUDE:

Hot encodes all the different longitude/latitude coordinates we have in our data, there are redundant coordinates for some of the id's so they are approximative in our dataset!

```{r}
# test <- lat_transf(test)
# test <- lon_transf(test)
```

## One hot encoding for VISIT holiday flag:

hot encodes as 1 if the date considered is holiday in Japan!

```{r}
# test <- vholflg_transf(test)
```

## One hot encoding for GENRE :

We get a lot of different levels for genre which is normal, but from the eda of the air csv files we see that some genres in the data are almost unvisited. It could be interesting to get only the significant genres (at least more than a thousand visits). You'll find that function in the feature engineering part, in any case here's the function that hot encodes all the different genres that are present in the air data: 

```{r}
# test <- genre_transf(test)
```

#2. One-hot encoding on reserve variables unaccessible for now:

```{r}
# try <- read.csv("complete_data_final.csv")
```

## One hot encoding for RESERVE day:

Same as visit, we one hot encode each day in a month for reservation dates:

```{r}
# try <- rday_transf(try)
```

## One hot encoding for RESERVE time:

In the reservation info we also have the time at which reservations were made for specific id's, we extract that info and one hot encode for all its levels (00:23):

```{r}
# try <- rtime_transf(try)
```

## One hot encoding for reserve MONTH:

Same principle as visit, hot encode month of reservation:

```{r}
# try <- rmonth_transf(try)
```

## One hot encoding for reserve YEAR:

and for reservation year...

```{r}
# try <- ryear_transf(try)
```

# One hot encoding for DAY OF THE WEEK RESERVE:

Hot encoding all days of the week for reservation dates:

```{r}
# try <- rdayweek_transf(try)
```

# One hot encoding for RESERVE holiday flag

One hot encodes reservation dates that are holidays in Japan, not very insisghtfull but we'll still consider it:

```{r}
# try <- rholflg_transf(try)
```

#3 One-hot encoding on feature engineered vairables:

All of the following are one hot encoding or new variables created from the original vars in our dataset to improve the XGB prediction!

## One hot encoding (Better version) AREA:

There are many different levels for area names, although they all appartain to one particular city. I'll regroup observations appartaining to the same big city (Tokyo, Kyoto, Osaka, etc...) and onehot encode on this smaller amount of levels.

```{r}
# test <- area_transf(test)
```

Difference is huge, we get 15 levels with the above function vs 130 from the basic one.

## one hot encoding for VISIT start/end of the month :

The idea behind this function is that costumers might be more encline to go to the restaurant in the first part of the month  rather than in the middel or at the end. So instead of creating dummies for each possible day in the month I'll just categorize them acoording to their situation in the month:

```{r}
# test <- bme_vmonth_transf(test)
```

## one hot encoding for regrouped GENRE :

Here we regroup genres that seems similar, for example we consider that Karoake, Party and Karaoke/Party fall within the same category, this allows to create less levels when hot encoding them!

```{r}
# test <- genre_gr_transf(test)
```

## one hot encoding for bar/restaurant separation:

Here we create a var that distinguishes between stores that are either Bars or Restaurants and then one hot encode them:

```{r}
# test <- barrest_transf(test)
```

## One hot encoding for golden week:

The golden week in Japan is a week with a series of holidays were Japan's economy slows down and consumption rises. It's a big event going on from the 28th of April to 6th of may so we hot encode it to get a var returning a one if the date falls within that time lapse:

```{r}
# test <- goldw_transf(test)
```

## One hot encoding for holiday days of the golden week

Same principle as above although we specifically take out the precise date of holidays:

```{r}
# test <- goldd_transf(test)
```

## One hot encoding for WEEKEND :

We saw on the EDA's that visits rised on weekend days (Friday to Sunday) which seems logical, so we hot encode for dates that correspond to weekend days:

```{r}
# test <- wknd_transf(test)
```

## one hot encoding for welth per area :

Basing ourselves on the distribution of wealth per area in Japan (GDP per capita) and given most of the id's are situated in the various departments of major cities in japan we create a varaible wealth categorizing the overall wealth of population given a certain area and one hot encode it according to mean GDP per capita per areas in Japan !

```{r}
# test <- wealth_transf(test)
```

## extract nth day of the year

Here we create a var giving which day in the 365 days in a year a specific date comes in, we do not need to one hot encode it since it's already a quantitative variable.

```{r}
# test <- nth_day_trasnf(test)
```

#4. Features only working for the data including reservation information:

Again given the same problem regarding reservation information we can't run these on our sample submission, although we keep them for any further progress we could potentially make if we find a way to integrate the reservation data:

## One hot encoding for NUMBER OF RES:

By counting the number of services for each date for each ID we can know how many reservations there were in a day. We can then also derive the average number of people per reservations:

```{r}
# try <- dn_transf(try)
```

## one hot encoding for LATENCY

Here we create a var computing the difference in days between the date of reservation and the actual visit to get an idea of how fancy a restaurant is. The idea behind this is that a restaurant being booked a month in advance is surely very popular (we even saw a booking more than a year in advance in the EDA's!)

```{r}
# try <- latency_transf(try)
```

## one hot encoding for RESERVE start/end of the month :

Same as for visit, but concerning reservation date! Surely combines well with latency var. 

```{r}
# try <- bme_rmonth_transf(try)
```

## one hot encoding for nb visits/reservation

Needs improvement, we get around 200 new columns from one hot encoding so we should create categories:
- small rest <= 20
- small/medium > 20 <= 50
- medium > 50 <= 90
- medium/large >90 <= 150
- large > 150

we can change according to preferences but here's the baseline of the function! (need to use case_when):

```{r}
# try <- average_transf(try)
```
